<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Lexical Normalization</title>
    <meta name="description" content="">
    <meta name="generator" content="VuePress 1.3.0">
    
    
    <link rel="preload" href="/github-nlp-progress/assets/css/0.styles.6033efd5.css" as="style"><link rel="preload" href="/github-nlp-progress/assets/js/app.03014354.js" as="script"><link rel="preload" href="/github-nlp-progress/assets/js/2.3456af6e.js" as="script"><link rel="preload" href="/github-nlp-progress/assets/js/3.937c9f03.js" as="script"><link rel="preload" href="/github-nlp-progress/assets/js/23.e1aedaab.js" as="script"><link rel="prefetch" href="/github-nlp-progress/assets/js/10.cb15689e.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/11.eabde15f.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/12.27303af9.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/13.1ecc9616.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/14.f7e0a6d6.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/15.c908a65f.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/16.77a77821.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/17.d273c85c.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/18.1090edb4.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/19.c36f96a3.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/20.c42e5144.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/21.179a6c72.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/22.49515d36.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/24.4385c2c6.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/25.84428cdb.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/26.120fe404.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/27.e84466dc.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/28.ecce4807.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/29.dd2817fc.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/30.28a3fb74.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/31.19988088.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/32.9a5cc67c.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/33.54b6fa31.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/34.c0e98bd0.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/35.2c79ac06.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/36.bff0078c.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/37.927d231a.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/38.005d0d92.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/39.3cadeae4.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/4.d939385a.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/40.58ef4623.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/41.b9c65150.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/42.af42e747.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/43.4dcb7194.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/44.dacd7b7a.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/45.54a535b7.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/46.0f0eff8a.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/47.5694acf3.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/48.946f37ab.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/49.34dda679.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/5.ffcec782.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/50.bba2f765.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/51.7cfe7fbe.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/52.1369c4c1.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/53.493d9eb5.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/54.9f32cbb0.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/55.cfc8e268.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/56.1ae5b816.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/57.15a35255.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/58.0cbba9ae.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/59.cc060eb2.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/6.075143cf.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/60.f667b9ec.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/61.4a173092.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/62.c3282d48.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/63.5a8e3369.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/64.fbab04ca.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/65.015dee23.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/7.51360b5e.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/8.1f2d5736.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/9.73d267d0.js">
    <link rel="stylesheet" href="/github-nlp-progress/assets/css/0.styles.6033efd5.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div id="global-layout" data-v-2be041bb><header class="bk-dark" data-v-2be041bb><video autoplay="autoplay" loop="loop" muted="muted" data-v-2be041bb><source src="/github-nlp-progress/assets/media/bk.417d52db.mp4" type="video/mp4" data-v-2be041bb></video> <div data-v-2be041bb><div class="header-content" data-v-2be041bb><h1 data-v-2be041bb>NLP-PROGRESS</h1> <h2 data-v-2be041bb>Repository to trasck the progress in Natural Language Processing (NLP), including the datasets and the current state-of-the-art for the most common NLP tasks.</h2> <a href="#" class="btn" data-v-2be041bb><i class="iconfont icon-github" data-v-2be041bb></i>
                    View on GitHub
                </a></div></div></header> <div class="theme-container no-navbar" data-v-2be041bb><!----> <div class="sidebar-mask"></div> <div class="sidebar-wrap sidebar-wrap-absolute"><!----></div> <main class="page"> <div class="theme-default-content content__default"><h1 id="lexical-normalization"><a href="#lexical-normalization" class="header-anchor">#</a> Lexical Normalization</h1> <p>Lexical normalization is the task of translating/transforming a non standard text to a standard register.</p> <p>Example:</p> <div class="language- extra-class"><pre class="language-text"><code>new pix comming tomoroe
new pictures coming tomorrow
</code></pre></div><p>Datasets usually consists of tweets, since these naturally contain a fair amount of
these phenomena.</p> <p>For lexical normalization, only replacements on the word-level are annotated.
Some corpora include annotation for 1-N and N-1 replacements. However, word
insertion/deletion and reordering is not part of the task.</p> <h3 id="lexnorm"><a href="#lexnorm" class="header-anchor">#</a> LexNorm</h3> <p>The <a href="http://people.eng.unimelb.edu.au/tbaldwin/etc/lexnorm_v1.2.tgz" target="_blank" rel="noopener noreferrer">LexNorm<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> corpus was originally introduced by <a href="http://aclweb.org/anthology/P/P11/P11-1038.pdf" target="_blank" rel="noopener noreferrer">Han and Baldwin (2011)<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.
Several mistakes in annotation were resolved by <a href="http://www.aclweb.org/anthology/D13-1007" target="_blank" rel="noopener noreferrer">Yang and Eisenstein<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>;
on this page, we only report results on the new dataset. For this dataset, the 2,577
tweets from <a href="http://www.aclweb.org/anthology/P14-3012" target="_blank" rel="noopener noreferrer">Li and Liu(2014)<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> is often
used as training data, because of its similar annotation style.</p> <p>This dataset is commonly evaluated with accuracy on the non-standard words. This
means that the system knows in advance which words are in need of normalization.</p> <table><thead><tr><th>Model</th> <th style="text-align:center;">Accuracy</th> <th>Paper / Source</th> <th>Code</th></tr></thead> <tbody><tr><td>MoNoise (van der Goot &amp; van Noord, 2017)</td> <td style="text-align:center;">87.63</td> <td><a href="http://www.let.rug.nl/rob/doc/clin27.paper.pdf" target="_blank" rel="noopener noreferrer">MoNoise: Modeling Noise Using a Modular Normalization System<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://bitbucket.org/robvanderg/monoise/" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Joint POS + Norm in a Viterbi decoding (Li &amp; Liu, 2015)</td> <td style="text-align:center;">87.58*</td> <td><a href="http://www.aaai.org/ocs/index.php/IJCAI/IJCAI15/paper/download/10839/10838" target="_blank" rel="noopener noreferrer">Joint POS Tagging and Text Normalization for Informal Text<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td></td></tr> <tr><td>Syllable based (Xu et al., 2015)</td> <td style="text-align:center;">86.08</td> <td><a href="http://www.aclweb.org/anthology/P15-1089" target="_blank" rel="noopener noreferrer">Tweet Normalization with Syllables<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td></td></tr> <tr><td>unLOL (Yang &amp; Eisenstein, 2013)</td> <td style="text-align:center;">82.06</td> <td><a href="http://www.aclweb.org/anthology/D13-1007" target="_blank" rel="noopener noreferrer">A Log-Linear Model for Unsupervised Text Normalization<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td></td></tr></tbody></table> <p>* used a slightly different version of the data</p> <h4 id="lexnorm2015"><a href="#lexnorm2015" class="header-anchor">#</a> LexNorm2015</h4> <p>The
<a href="https://github.com/noisy-text/noisy-text.github.io/blob/master/2015/files/lexnorm2015.tgz" target="_blank" rel="noopener noreferrer">LexNorm2015<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
dataset was introduced for the shared task on lexical normalization, hosted at
WNUT2015 (<a href="http://aclweb.org/anthology/W15-4319" target="_blank" rel="noopener noreferrer">Baldwin et al(2015)<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>).  In
this dataset, 1-N and N-1 replacements are included in the annotation. The
evaluation metrics used are precision, recall and F1 score. However, this is
calculated a bit odd:</p> <p>Precision: out of all necessary replacements, how many correctly found</p> <p>Recall: out of all normalization by system, how many correct</p> <p>This means that if the system replaces a word which is in need of normalization,
but chooses the wrong normalization, it is penalized twice.</p> <table><thead><tr><th>Model</th> <th style="text-align:center;">F1</th> <th style="text-align:center;">Precision</th> <th style="text-align:center;">Recall</th> <th>Paper / Source</th> <th>Code</th></tr></thead> <tbody><tr><td>MoNoise (van der Goot &amp; van Noord, 2017)</td> <td style="text-align:center;">86.39</td> <td style="text-align:center;">93.53</td> <td style="text-align:center;">80.26</td> <td><a href="http://www.let.rug.nl/rob/doc/clin27.paper.pdf" target="_blank" rel="noopener noreferrer">MoNoise: Modeling Noise Using a Modular Normalization System<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://bitbucket.org/robvanderg/monoise/" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Random Forest + novel similarity metric (Jin, 2017)</td> <td style="text-align:center;">84.21</td> <td style="text-align:center;">90.61</td> <td style="text-align:center;">78.65</td> <td><a href="http://www.aclweb.org/anthology/W15-4313" target="_blank" rel="noopener noreferrer">NCSU-SAS-Ning: Candidate Generation and Feature Engineering for Supervised Lexical Normalization<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td></td></tr></tbody></table> <p><a href="/github-nlp-progress/" class="router-link-active">Go back to the README</a></p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div> <footer class="bk-dark" data-v-2be041bb><div class="footer-content" data-v-2be041bb><p data-v-2be041bb>Published with GitHub Pages</p></div></footer></div><div class="global-ui"></div></div>
    <script src="/github-nlp-progress/assets/js/app.03014354.js" defer></script><script src="/github-nlp-progress/assets/js/2.3456af6e.js" defer></script><script src="/github-nlp-progress/assets/js/3.937c9f03.js" defer></script><script src="/github-nlp-progress/assets/js/23.e1aedaab.js" defer></script>
  </body>
</html>
